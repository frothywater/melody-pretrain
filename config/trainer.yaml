# lightning.pytorch==1.8.3.post1
seed_everything: 42
trainer:
  callbacks:
    - class_path: StochasticWeightAveraging
      init_args:
        swa_lrs: 1e-2
    - class_path: LearningRateMonitor
      init_args:
        logging_interval: step
    - class_path: ModelCheckpoint
      init_args:
        save_top_k: 1
        monitor: val_loss
        mode: min
        filename: "{epoch:02d}-{train_loss:.3f}-{val_loss:.3f}"
    - class_path: ModelCheckpoint
      init_args:
        save_top_k: 1
        monitor: step
        mode: max
        filename: "{epoch:02d}-{train_loss:.3f}-{val_loss:.3f}-{step}"
  gradient_clip_val: 1.0
  devices: 1
  max_steps: 5000
  log_every_n_steps: 1
  accelerator: gpu
  strategy:
    class_path: DDPStrategy
    init_args:
      find_unused_parameters: false
  precision: 16
  accumulate_grad_batches: 16
data:
  batch_size: 16
  num_workers: 4

# debug
# trainer:
#   fast_dev_run: 100
#   profiler:
#     class_path: PyTorchProfiler
#     init_args:
#       filename: profile_result
#       group_by_input_shapes: true
#       record_module_names: true
#       sort_by_key: cuda_memory_usage
#       row_limit: -1
#     dict_kwargs:
#       profile_memory: true
#       record_shapes: true